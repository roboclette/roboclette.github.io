<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Roboclette">
<meta name="author" content="Sylvain Calinon">
<title>Roboclette</title>
<link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
<!-- Custom fonts
<link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
-->
<link href="https://fonts.googleapis.com/css?family=Open+Sans:700,400,300" rel="stylesheet">
<link href="css/style.css" rel="stylesheet">
</head>

<body id="page-top">

<!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-light bg-light fixed-top" id="mainNav">
  <div class="container">
    <a class="navbar-brand js-scroll-trigger" href="#page-top"><img height="40px" src="images/roboclette-logo01.svg"></a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#project">Project</a>
        </li>
		<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#how">How it works</a>
        </li>
		<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#lfd">Research</a>
        </li>
		<!--
		<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#team">Team</a>
        </li>
		<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#events">Events</a>
        </li>
		-->
		<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#partners">Partners</a>
        </li>
      </ul>
    </div>
  </div>
</nav>


<header>
<div class="container text-center">
	<img width="80%" src="images/roboclette-logo01.svg" class="img-fluid mx-auto d-block">
</div>
</header>

<section id="video" class="bg-light">
<div class="container">
	<div class="embed-responsive embed-responsive-16by9"><iframe class="embed-responsive-item" src="https://www.youtube.com/embed/w0in0Lr0FbU?cc_load_policy=1&loop=1&modestbranding=1&rel=0&showinfo=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div>
</section>

<section id="project">
<div class="container">
	<h2>When a robot learns how to make traditional Swiss raclette thanks to AI</h2>
	<div class="row">
		<div class="col-lg-12 mx-auto">

		<p>It took the know-how of the cheese Master Eddy Baillifard, founder of Raclett'House, and the expertise of the Robot learning & interaction group from the Idiap research institute to achieve the first raclette made by a robot. Beyond the technical challenge, the project shows the potential of learning from demonstration techniques and for a better human-robot collaboration.</p>

		<p>The cheese master hand is quick and smooth: he applies a precisely controlled pressure on the melting cheese surface to let it land on the plate. Et voilà, the famous Swiss raclette! The gesture seems easy, but the know-how behind it is crucial. Every raclette enthusiast can testify how hard it is to master this apparently simple skill. “Depending on the type of raclette cheese, the surface can vary in terms of softness and can be more or less fluid,” says Eddy Baillifard, the Master and ambassador of the raclette cheese. Mimicking this skill with a robot isn't easy. To achieve this, Emmanuel Pignat, a PhD from the Idiap's robotic group used a novel approach: Eddy guided the robot's arm to let it record the movements and forces needed to perform the task. This learning technique allows to transfer skills from the human to the robot in an intuitive manner. The range of applications is wide, including industrial robots, service robots, and assistive robots. It relieves professionals of their most repetitive, dangerous or uncomfortable duties, in order to spend more time using their human skills, such as supervision, evaluation or decision making.</p>

		<h2>A smart raclette</h2>

		<p>If learning from demonstration – the scientific term for copying a gesture – seems an obvious task to us humans, the challenge is much harder for robots. They are usually programmed for a specific task, which is repeated accurately in a loop. “Thanks to artificial intelligence algorithms, the robotic arm can generate movements that can adapt to new situations. In this specific case, the cheese can be in slightly different positions and orientations, and there can be more or less cheese left in the oven,” says Sylvain Calinon, head of Idiap's Robot learning & interaction group. “This ability to adapt is the key to allow efficient human-robot collaboration. The cheese Master shows each time a slightly different way to scrape the raclette cheese onto the plate. The underlying learning algorithms allows the robot to integrate these nuances to recreate a meaningful gesture in a new situation.”</p>

		<h2>When tradition meets innovation</h2>

		<p>This collaboration between the cheese Master and the researchers was supported by the whole Canton of Valais. The local authorities brought their financial support to this scientific research. The TTM company created a specific oven with a handle for the robot to grab the plate with the cheese. Nicolas Fontaine, a young local entrepreneur, facilitated the contacts between TTM, Raclett'House and Valais/Wallis Promotion which made the film. “When Nicolas Fontaine asked us for help, we immediately decided to help. This project highlights our strong belief about Valais: it's a unique territory mixing tradition and innovation. Both are represented by the best people and skills as illustrated in this short film,” says Alessandro Marcolin, marketing director of Valais/Wallis Promotion.</p>

		</div>
	</div>
</div>
</section>


<section id="how" class="bg-light">
<div class="container">
	<h2>How it works</h2>
	<div class="row">
		<div class="col-lg-6 mx-auto">
			<figure class="figure p-3">
			<img class="figure-img img-fluid" src="images/3d01.jpg">
			<figcaption class="figure-caption">Learning from demonstration provides an intuitive approach to reprogram robots.</figcaption>
			</figure>
		</div>
		<div class="col-lg-6 mx-auto">
			<figure class="figure p-3">
			<img class="figure-img img-fluid" src="images/3d02.jpg">
			<figcaption class="figure-caption">The robot records positions, orientations, velocities and accelerations that are taught through multiple demonstrations.</figcaption>
			</figure>
		</div>
	</div>
	<div class="row">
		<div class="col-lg-6 mx-auto">
			<figure class="figure p-3">
			<img class="figure-img img-fluid" src="images/3d03.jpg">
			<figcaption class="figure-caption">It can then exploit these variations to adapt its movements to new situations.</figcaption>
			</figure>
		</div>
		<div class="col-lg-6 mx-auto">
			<figure class="figure p-3">
			<img class="figure-img img-fluid" src="images/3d04.jpg">
			<figcaption class="figure-caption">A sensor measures the applied force to let the robot adapt its gesture. Here, the robot has learned that it needs to apply a precise force instead of a motion at a precise height, while keeping a constant speed to execute the movement.</figcaption>
			</figure>
		</div>
	</div>
</div>
</section>


<section id="lfd">
<div class="container">
	<div class="row">
		<div class="col-lg-6 p-3 mx-auto">
			<h2>Robot Learning and Interaction</h2>
			<p>The Robot Learning & Interaction group at the Idiap Research Institute develops approaches for human-robot collaboration and robot programming from demonstration.</p>
			<p>The goal is to transfer new skills to robots in an intuitive manner, by conceiving user-friendly interfaces and algorithms to let a robot learn new skills by imitation, instead of having to reprogram the robot through a computer language.</p>
		</div>
		<div class="col-lg-6 p-3 mx-auto">
			<img class="figure-img img-fluid" src="images/lfd01.jpg">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-6 p-3 mx-auto">
			<h2>Various applications</h2>
			<ul>
			<li>Robots close to us (industrial, service and assistive robots);</li>
			<li>Robots part of us (prosthesis and exoskeleton);</li>
			<li>Robots far away from us (teleoperation of distant robots).</li>
			</ul>
		</div>
		<div class="col-lg-6 p-3 mx-auto">
			<h2>New perspectives in robotics</h2>
			<ul>
			<li>For SMEs that frequently need to reprogram their machines (small series, personalized products, changes of tasks assignment);</li>
			<li>For many new applications arising in robotics, including collaborative robots sharing our workspaces and achieving joint operations with us.</li>
			</ul>
		</div>
	</div>	
	
	<div class="row">
		<div class="col-lg-4 p-3 mx-auto">
			<figure class="figure text-center">
			<img class="figure-img img-fluid" src="images/lfd_challenges01.jpg">
			<figcaption class="figure-caption">Observational learning</figcaption>
			</figure>
		</div>
		<div class="col-lg-4 p-3 mx-auto">
			<figure class="figure text-center">
			<img class="figure-img img-fluid" src="images/lfd_challenges02.jpg">
			<figcaption class="figure-caption">Kinesthetic teaching</figcaption>
			</figure>
		</div>
		<div class="col-lg-4 p-3 mx-auto">
			<figure class="figure text-center">
			<img class="figure-img img-fluid" src="images/lfd_challenges03.jpg">
			<figcaption class="figure-caption">Correspondence problems</figcaption>
			</figure>
		</div>
	</div>

	<h2>Learning approaches</h2>
	<div class="row">
		<div class="col-lg-6 p-1 mx-auto">
			<ul>
			<li>By observing gestures from cameras mounted on the robot;</li>
			<li>By distant teleoperation;</li>
			<li>By guiding the robot by hand (kinesthetic teaching).</li>
			</ul>
		</div>
		<div class="col-lg-6 p-1 mx-auto">
			<p>Behind these approaches, the developed mathematical models have different objectives (recognition, prediction, synthesis), and are shared by multiple learning modalities (imitation and exploration).</p>
		</div>
	</div>	

</div>
</section>


<!--
<section id="team">
<div class="container">
	<h2>Team</h2>
	<div class="row">
		<div class="col-lg-3 mx-auto text-center">
			<b>Emmanuel Pignat</b><br>Creator
		</div>	
		<div class="col-lg-3 mx-auto text-center">
			<b>Sylvain Calinon</b><br>Research Coordinator
		</div>
		<div class="col-lg-3 mx-auto text-center">
			<b>Nicolas Fontaine</b><br>Operations Coordinator, Logistics
		</div>
		<div class="col-lg-3 mx-auto text-center">
			<b>Eddy Baillifard</b><br>Cheese Master
		</div>
	</div>
</div>
</section>
-->


<section id="partners">
<div class="container">
	<h2>Partners</h2>
	<div class="row">
		<div class="col-lg-3 p-3 mx-auto my-auto text-center">
			<img class="figure-img img-fluid" src="images/Idiap-logo01.png">
			<!--<b>Idiap Research Institute</b>-->
		</div>
		<div class="col-lg-3 p-5 mx-auto my-auto text-center">
			<img class="figure-img img-fluid" src="images/RaclettHouse-logo01.jpg">
			<!--<b>Raclett'House</b>-->
		</div>
		<div class="col-lg-3 p-3 mx-auto my-auto text-center">
			<img class="figure-img img-fluid" src="images/Franka-logo01.jpg">
			<!--<b>Franka Emika</b>-->
		</div>
		<div class="col-lg-3 p-5 mx-auto my-auto text-center">
			<img class="figure-img img-fluid" src="images/TTM-logo01.png">
			<!--<b>TTM</b>-->
		</div>
	</div>
	<br>
	<div class="row">
		<div class="col-lg-4 p-3 mx-auto my-auto text-center">
			<img class="figure-img img-fluid" src="images/Valais-logo01.png">
			<!--<b>State of Valais</b>-->
		</div>
		<div class="col-lg-4 p-5 mx-auto my-auto text-center">
			<img class="figure-img img-fluid" src="images/VS-prom-logo01.jpg">
			<!--<b>Valais/Wallis Promotion</b>-->
		</div>
		<div class="col-lg-4 p-5 mx-auto my-auto text-center">
			<img class="figure-img img-fluid" src="images/presence-logo01.png">
			<!--<b>Presence Switzerland</b>-->
		</div>
	</div>
</div>
</section>

<br><br><br>


<!--
<h2>More information</h2>

<p>The learning approach behind this application is described in this scientific publication, with the related video. Another example of application of this approach is to teach robots to assist elderly or disabled people to get dressed, described here, with related video.</p>

The original video is available here.

Partners involved in the project:

Idiap Robot Learning & Interaction group
Raclett’House
Raclette oven TTM
Valais/Wallis Promotion
-->


<!--
<section id="publications" class="bg-light">
<div class="container">
<div class="row">
<div class="col-lg-12 mx-auto">
<h2>Publications</h2>
<p>
<ul>
<li></li>
</ul>
</p>
</div>
</div>
</div>
</section>


<section id="team">
<div class="container">
<div class="row">
	<div class="col-lg-12 mx-auto">
	<h2>Consortium</h2>
	<div class="container">
	<div class="row">
		<div class="col-lg-4 text-center my-auto">
		<a href="http://www.idiap.ch/en" target="_BLANK"><img src="images/Idiap.png" class="img-fluid"></a>
		</div>
		<div class="col-lg-4 text-center my-auto">
		<a href="https://www.iit.it/" target="_BLANK"><img src="images/IIT.png" class="img-fluid"></a>
		</div>
		<div class="col-lg-4 text-center my-auto">
		<a href="https://www.ec-lyon.fr/en" target="_BLANK"><img src="images/ECL.png" class="img-fluid"></a>
		</div>
	</div>
	<div class="row">
		<div class="col-lg-4 text-center my-auto">
		<a href="http://www.idiap.ch/en" target="_BLANK"><h5 class="mb-3">Idiap Research Institute</h5></a>
		</div>
		<div class="col-lg-4 text-center my-auto">
		<a href="https://www.iit.it/" target="_BLANK"><h5 class="mb-3">Italian Institute of Technology</h5></a>
		</div>
		<div class="col-lg-4 text-center my-auto">
		<a href="https://www.ec-lyon.fr/en" target="_BLANK"><h5 class="mb-3">École Centrale de Lyon</h5></a>
		</div>
	</div>
	<div class="row">
		<div class="col-lg-4 text-center">
		<p class="text-muted mb-0">Members:</p>
		<p class="text-muted mb-0"><a href="http://calinon.ch/" target="_BLANK">Sylvain Calinon</a></p>
		<p class="text-muted mb-0"><a href="http://andreanjos.org/" target="_BLANK">André Anjos</a></p>
		<p class="text-muted mb-0"><a href="http://www.idiap.ch/~marcel/professional/Welcome.html" target="_BLANK">Sébastien Marcel</a></p>
		</div>
		<div class="col-lg-4 text-center">
		<p class="text-muted mb-0">Members:</p>
		<p class="text-muted mb-0"><a href="https://www.linkedin.com/in/fei-chen-55662388/?originalSubdomain=it" target="_BLANK">Fei Chen</a></p>
		<p class="text-muted mb-0"><a href="https://www.linkedin.com/in/andreaincertidelmonte/" target="_BLANK">Andrea Incerti Delmonte</a></p>
		</div>
		<div class="col-lg-4 text-center">
		<p class="text-muted mb-0">Members:</p>
		<p class="text-muted mb-0"><a href="http://perso.ec-lyon.fr/liming.chen/" target="_BLANK">Liming Chen</a></p>
		<p class="text-muted mb-0"><a href="https://www.researchgate.net/profile/Maxime_Petit4" target="_BLANK">Maxime Petit</a></p>
		</div>
	</div>

	</div>
	</div>
</div>
</div>
</section>
-->



<!-- Footer <small><pre class="text-light" > -->
<!--
<footer class="py-5 bg-dark">
<div class="container">
<p class="text-light">
Learn-Real is a collaborative project supported by <a href="http://www.snf.ch/en/Pages/default.aspx" target="_BLANK">SNSF</a> (Switzerland), <a href="http://www.miur.gov.it/" target="_BLANK">MIUR</a> (Italy), and <a href="http://www.agence-nationale-recherche.fr/en/" target="_BLANK">ANR</a> (France), through the <a href="http://www.chistera.eu/call-2017-announcement" target="_BLANK">ERA-NET CHIST-ERA 2017 Call ORMR</a> (Object recognition and manipulation by robots: Data sharing and experiment reproducibility).
</p>
<p class="text-muted">
The Learn-Real logo can be generated from a Linux command line (if the Candice font is not available on your system, it can be replaced by another font):
</p>
<p style="font-size: x-small; line-height: 80%;"><code>
convert -size 400x400 -virtual-pixel tile xc: +noise Random -blur 0x1 -channel G -evaluate add 40% -separate pattern.png<br>
convert -size 1720x520 xc:white -font Candice -pointsize 288 -stroke black -strokewidth 100 -annotate +100+344 'Learn-Real' -blur 0x32 -resize 25% -ordered-dither o8x8,6 -resize 400% background.png<br>
convert -size 1720x520 xc:none -font Candice -pointsize 288 -fill 'cmyka(100%,0%,0%,0%,0.8)' -stroke 'cmyka(100%,0%,0%,0%,0.8)' -strokewidth 40 -annotate +88+340 'Learn-Real' -channel RGBA -wave 8x40 c_layer.png<br>
convert -size 1720x520 xc:none -font Candice -pointsize 288 -fill 'cmyka(0%,100%,0%,0%,0.8)' -stroke 'cmyka(0%,100%,0%,0%,0.8)' -strokewidth 40 -annotate +112+340 'Learn-Real' -channel RGBA -wave 8x40 m_layer.png<br>
convert -size 1720x520 xc:none -font Candice -pointsize 288 -fill 'cmyka(0%,0%,100%,0%,0.8)' -stroke 'cmyka(0%,0%,100%,0%,0.8)' -strokewidth 40 -annotate +100+340 'Learn-Real' -channel RGBA -rotate -90 -wave 8x40 -rotate +90 y_layer.png<br>
convert -size 1720x520 xc:none -font Candice -pointsize 288 -fill tile:pattern.png -stroke black -strokewidth 20 -annotate +100+344 'Learn-Real' -stroke none -annotate +100+344 'Learn-Real' -ordered-dither o8x8,6 foreground.png<br>
convert \( c_layer.png null: m_layer.png -compose multiply -layers Composite \) null: y_layer.png -compose multiply -layers Composite cmy_layer.png<br>
convert \( background.png null: cmy_layer.png -layers Composite \) null: foreground.png -layers Composite logo.png
</code></p>
<p class="text-muted">
The use of a command line to generate the logo evokes the synthetic image rendering and reproducibility aspects of the project. It also alludes to the exploitation of existing tools in new contexts, as we do in Learn-Real through the use of the Beat platform for the benchmarking of robot manipulation tasks. The white noise texture and the superposed CMYK colored layers allude to the variational aspects, which are central to the learning aspects of the project. The dithered background evokes the rendering techniques employed in early video games, referring to the use in the project of engines (simulators) and interfaces (head-mounted displays) originating from the video game industry.
</p>
</div>
</footer>
-->


<!-- Bootstrap core JavaScript -->
<script src="vendor/jquery/jquery.min.js"></script>
<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

<!-- Plugin JavaScript -->
<script src="vendor/jquery-easing/jquery.easing.min.js"></script>

<!-- Custom JavaScript for this theme -->
<script src="js/scrolling-nav.js"></script>

</body>
</html>
